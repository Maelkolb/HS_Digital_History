import nltk
from nltk import FreqDist
import matplotlib.pyplot as plt

nltk.download('punkt')
nltk.download('stopwords')

# Dateipfad
file_path = 'cleaned_lemmatized_text_KG-full.txt'

words_to_analyze = ['jew', 'jewish']

words_to_analyse2 = ['heresy', 'heresiarchs', 'menander', 'simon magus', 'simon', 'ebionite', 'cerinthus', 'cerinthian', 'nicolaus', 'nicolaitans',
                   'saturninus', 'saturnilians', 'basilides', 'basilidians', 'carpocratians', 'carpocrates', 'valentinus',
                    'valentinians', 'cerdon', 'marc magus', 'marcion', 'marcions', 'tatian', 'tatians', 'severus', 'severians',
                   'bardesanes', 'apelles', 'montanus', 'florinus', 'blastus', 'artemon', 'theodotus', 'beryllus', 'the dissension of the arabian',
                   'elkesites', 'novatus', 'sabellius', 'paul of samosata', 'manichean']

words_to_analyse3 = ['constantine']

# Funktion zum Einlesen des Textkorpus aus der Datei
def read_corpus_from_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

# Funktion zum Bereinigen und Tokenisieren des Textkorpus
def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    stop_words = set(nltk.corpus.stopwords.words('german'))
    return [word for word in tokens if word.isalnum() and word not in stop_words]

text_corpus = read_corpus_from_file(file_path)

# Pre-Processing
filtered_tokens = preprocess_text(text_corpus)

# Segmentierung
segment_size = len(filtered_tokens) // 10

# Frequenzanalyse f체r jede Wortliste 
segment_frequencies = {word_list: [] for word_list in ['words_to_analyze', 'words_to_analyse2', 'words_to_analyse3']}

for i in range(10):
    segment_start = i * segment_size
    segment_end = (i + 1) * segment_size
    segment = filtered_tokens[segment_start:segment_end]
    freq_dist = FreqDist(segment)
    
    for word_list in ['words_to_analyze', 'words_to_analyse2', 'words_to_analyse3']:
        segment_frequency = sum(freq_dist[word] for word in eval(word_list))
        segment_frequencies[word_list].append(segment_frequency)

# Visualisierung
plt.figure(figsize=(10, 6))

colors = ['blue', 'green', 'red']

for i, word_list in enumerate(['words_to_analyze', 'words_to_analyse2', 'words_to_analyse3']):
    plt.bar([x + i * 0.2 for x in range(1, 11)], segment_frequencies[word_list], width=0.2, color=colors[i])

plt.title(f'H채ufigkeit der Wortlisten im Korpus')
plt.xlabel('Segment')
plt.ylabel('Absolute H채ufigkeit')

plt.legend(['Judentum', 'H채resien', 'Konstantin'])

plt.grid(True)
plt.savefig('all_words_frequency.png', format='png')
plt.show()
